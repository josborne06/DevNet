# ðŸ¤– AI Agents 101 â€“ Cisco Live 2025 Summary
**Speaker**: Tim Miller, Solutions Engineer at Cisco  
**Session Focus**: Building autonomous, trustworthy, and practical AI agents  
**Transcript**: [Otter.ai Full Transcript](https://otter.ai/u/arkVyjPgD2jyI1uzGrt0SADTni8)

---

## ðŸ§  Core Idea
AI agents are evolving from basic assistants into autonomous systems that:
- Make decisions
- Pull real-time data
- Communicate with other agents
- Improve over time

---

## ðŸ§° Key Concepts

### ðŸ”¹ AI Agents vs Assistants
- Agents operate **independently** and **proactively**
- Agents require structure, memory, and reasoning layers  
ðŸ“˜ [Outshift Blog â€“ Agent Taxonomy](https://outshift.cisco.com/blog/building-ai-agents)  

### ðŸ”¹ Frameworks & Tools
- ðŸ› ï¸ **LangChain**: [langchain.com](https://www.langchain.com/)
- âœï¸ **Prompt Engineering**: [Prompt Engineering Guide](https://github.com/dair-ai/Prompt-Engineering-Guide)
- ðŸ§  **Retrieval-Augmented Generation (RAG)**: [RAG Overview by Meta](https://ai.meta.com/blog/retrieval-augmented-generation-retrieval-llm/)
- ðŸ“¦ **Model Context Protocol (MCP)**: [Outshift MCP Intro](https://outshift.cisco.com/blog/model-context-protocol/)
- ðŸ¤– **Agent-to-Agent Protocol (A2A)**: [Cisco AI Agent Stack Overview](https://outshift.cisco.com/solutions/ai-agents)

### ðŸ”¹ AI Model Selection
- ðŸ¤– [OpenAI Models](https://platform.openai.com/docs/models)
- ðŸ¤– [Anthropic Claude](https://www.anthropic.com/index/claude)
- ðŸ¤– [Hugging Face Model Hub](https://huggingface.co/models)
- ðŸ“ [Model Cards](https://huggingface.co/docs/hub/model-cards) â€“ documentation on how models behave

### ðŸ”¹ Agent Autonomy Levels
Inspired by Outshiftâ€™s 5-Level Autonomy system:
1. Deterministic automation
2. Conditional logic
3. Prompt-driven LLM
4. Tool-using agent
5. Autonomous planner with goals

ðŸ“– [Autonomy Levels Reference](https://outshift.cisco.com/blog/building-ai-agents)

---

## ðŸ› ï¸ Example Project: Essay Writer Agent (LangChain)
Tim demoed an agent with:
- **Planning Phase** â€“ Define topic and intent
- **Research Phase** â€“ Pull real-time info using RAG
- **Writing Phase** â€“ Generate structured output

Each phase used refined prompts for better accuracy.

ðŸ”— [LangChain Agent Example Docs](https://docs.langchain.com/docs/modules/agents)

---

## ðŸ” Security & Agent Coordination
- **MCP** â€“ [Model Context Protocol Overview](https://outshift.cisco.com/blog/model-context-protocol/)
- **A2A Protocol** â€“ Enables discovery, identity verification, and secure agent interaction  
ðŸ” [Secure Multi-Agent Systems](https://outshift.cisco.com/blog/secure-agent-interaction)

---

## âœ… Action Items

- [ ] Explore foundational LLMs: OpenAI, Hugging Face, Anthropic
- [ ] Learn the LangChain framework
- [ ] Practice structured prompt engineering techniques
- [ ] Understand and implement RAG-based solutions
- [ ] Dive into MCP & A2A protocols for AI interoperability

---

## ðŸ”® Final Thoughts
> "AI agents are the future of intelligent automation â€” theyâ€™ll plan, research, decide, and collaborate. What APIs were to the 2010s, agents are to the 2020s."

Stay connected, experiment, and iterate.  
The future is autonomous â€” and you can build it.

---